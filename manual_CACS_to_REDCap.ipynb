{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b358f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom as dicom\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995742c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109193f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='H:/My Desktop/sr_files' #Path with SR DICOM files with measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d5818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"H:/My Desktop/CACS_manual_new\" #path to save txt files to be used to create df\n",
    "\n",
    "if not os.path.exists(save_path): #Create folder to save images\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e30f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('135984', 1),\n",
       " ('136449', 1),\n",
       " ('136567', 1),\n",
       " ('141168', 1),\n",
       " ('145677', 1),\n",
       " ('158883', 1),\n",
       " ('166198', 1),\n",
       " ('171539', 1),\n",
       " ('177488', 1),\n",
       " ('182367', 1),\n",
       " ('183377', 1),\n",
       " ('188150', 1),\n",
       " ('195806', 1),\n",
       " ('198107', 1),\n",
       " ('203629', 1),\n",
       " ('211569', 1),\n",
       " ('212333', 1),\n",
       " ('220228', 1),\n",
       " ('221349', 1),\n",
       " ('224428', 1),\n",
       " ('228777', 1),\n",
       " ('229541', 1),\n",
       " ('230268', 1),\n",
       " ('233118', 1),\n",
       " ('240819', 1),\n",
       " ('247747', 1),\n",
       " ('248597', 1),\n",
       " ('251710', 1),\n",
       " ('255514', 1),\n",
       " ('255649', 1),\n",
       " ('262895', 1),\n",
       " ('266477', 1),\n",
       " ('275872', 1),\n",
       " ('282702', 1),\n",
       " ('285527', 1),\n",
       " ('293158', 1),\n",
       " ('293967', 1),\n",
       " ('294224', 1),\n",
       " ('295772', 1),\n",
       " ('296768', 1),\n",
       " ('297674', 1),\n",
       " ('301013', 1),\n",
       " ('306167', 1),\n",
       " ('316249', 1),\n",
       " ('316867', 1),\n",
       " ('327664', 1),\n",
       " ('330189', 1),\n",
       " ('332758', 1),\n",
       " ('338683', 1),\n",
       " ('341948', 1),\n",
       " ('346061', 1),\n",
       " ('346603', 1),\n",
       " ('347137', 1),\n",
       " ('349299', 1),\n",
       " ('368158', 1),\n",
       " ('369762', 1),\n",
       " ('377008', 1),\n",
       " ('378327', 1),\n",
       " ('379271', 1),\n",
       " ('384563', 1),\n",
       " ('394676', 1),\n",
       " ('396349', 1),\n",
       " ('397588', 1),\n",
       " ('416820', 1),\n",
       " ('420411', 1),\n",
       " ('423038', 1),\n",
       " ('424104', 1),\n",
       " ('424517', 1),\n",
       " ('425409', 1),\n",
       " ('427158', 1),\n",
       " ('430437', 1),\n",
       " ('440977', 1),\n",
       " ('446215', 1),\n",
       " ('449238', 1),\n",
       " ('449790', 1),\n",
       " ('452500', 1),\n",
       " ('454919', 1),\n",
       " ('457925', 1),\n",
       " ('459518', 1),\n",
       " ('466979', 1),\n",
       " ('468555', 1),\n",
       " ('473163', 1),\n",
       " ('475503', 1),\n",
       " ('477207', 1),\n",
       " ('479390', 1),\n",
       " ('485005', 1),\n",
       " ('488597', 1),\n",
       " ('492022', 1),\n",
       " ('501237', 1),\n",
       " ('502129', 1),\n",
       " ('505017', 1),\n",
       " ('516192', 1),\n",
       " ('526347', 1),\n",
       " ('529988', 1),\n",
       " ('535068', 1),\n",
       " ('537519', 1),\n",
       " ('559804', 1),\n",
       " ('565439', 1),\n",
       " ('568150', 1),\n",
       " ('570887', 1),\n",
       " ('573657', 1),\n",
       " ('582618', 1),\n",
       " ('583826', 1),\n",
       " ('587446', 1),\n",
       " ('588807', 1),\n",
       " ('592863', 1),\n",
       " ('599086', 1),\n",
       " ('602977', 1),\n",
       " ('605136', 1),\n",
       " ('605723', 1),\n",
       " ('607045', 1),\n",
       " ('608357', 1),\n",
       " ('615541', 1),\n",
       " ('616599', 1),\n",
       " ('617554', 1),\n",
       " ('624588', 1),\n",
       " ('627587', 1),\n",
       " ('627747', 1),\n",
       " ('632157', 1),\n",
       " ('634868', 1),\n",
       " ('639283', 1),\n",
       " ('639745', 1),\n",
       " ('641569', 1),\n",
       " ('649525', 1),\n",
       " ('652571', 1),\n",
       " ('664017', 1),\n",
       " ('665749', 1),\n",
       " ('670753', 1),\n",
       " ('671114', 1),\n",
       " ('682768', 1),\n",
       " ('688766', 1),\n",
       " ('695467', 1),\n",
       " ('699976', 1),\n",
       " ('703242', 1),\n",
       " ('705786', 1),\n",
       " ('706029', 1),\n",
       " ('706449', 1),\n",
       " ('709257', 1),\n",
       " ('710363', 1),\n",
       " ('716045', 1),\n",
       " ('716309', 1),\n",
       " ('718461', 1),\n",
       " ('721837', 1),\n",
       " ('725957', 1),\n",
       " ('726936', 1),\n",
       " ('742396', 1),\n",
       " ('743691', 1),\n",
       " ('750618', 1),\n",
       " ('754238', 1),\n",
       " ('756994', 1),\n",
       " ('757959', 1),\n",
       " ('760443', 1),\n",
       " ('760658', 1),\n",
       " ('764181', 1),\n",
       " ('784352', 1),\n",
       " ('789319', 1),\n",
       " ('794632', 1),\n",
       " ('799304', 1),\n",
       " ('807856', 1),\n",
       " ('808262', 1),\n",
       " ('809796', 1),\n",
       " ('810833', 1),\n",
       " ('810906', 1),\n",
       " ('814939', 1),\n",
       " ('817605', 1),\n",
       " ('819816', 1),\n",
       " ('833596', 1),\n",
       " ('841818', 1),\n",
       " ('842460', 1),\n",
       " ('854364', 1),\n",
       " ('856186', 1),\n",
       " ('861138', 1),\n",
       " ('863165', 1),\n",
       " ('864484', 1),\n",
       " ('869330', 1),\n",
       " ('871178', 1),\n",
       " ('872428', 1),\n",
       " ('873698', 1),\n",
       " ('873872', 1),\n",
       " ('883218', 1),\n",
       " ('883558', 1),\n",
       " ('898468', 1),\n",
       " ('900818', 1),\n",
       " ('900936', 1),\n",
       " ('905504', 1),\n",
       " ('910698', 1),\n",
       " ('920947', 1),\n",
       " ('924470', 1),\n",
       " ('933191', 1),\n",
       " ('935673', 1),\n",
       " ('939613', 1),\n",
       " ('939651', 1),\n",
       " ('945397', 1),\n",
       " ('945484', 1),\n",
       " ('947744', 1),\n",
       " ('960629', 1),\n",
       " ('964607', 1),\n",
       " ('966450', 1),\n",
       " ('967939', 1),\n",
       " ('979642', 1),\n",
       " ('981720', 1),\n",
       " ('984618', 1),\n",
       " ('989502', 1),\n",
       " ('991739', 1),\n",
       " ('993006', 1),\n",
       " ('997251', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract file names from the list of files in the path and count their occurrence\n",
    "files=[file.split('_')[1].split('.')[0] for file in os.listdir(path)]\n",
    "Counter(files).most_common() #Check if same participant exists more than once - should not be, otherwise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb446ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to recursively loop over attributes in DICOM file to get numbers for each CAC score\n",
    "def recurse(ds,open_path): \n",
    "\n",
    "    for index,elem in enumerate(ds): #Loop over elements in the DICOM file\n",
    "            \n",
    "        if elem.tag==(0x0040a730): #If the attribute is 'Content Sequence' keep looping inside it - call function again\n",
    "            [recurse(item,open_path) for item in elem.value] \n",
    "            \n",
    "        else:\n",
    "            if isinstance(elem.value,str)!=1: #If the attribute is not string - will be numeric value or CAC attribute\n",
    "               \n",
    "                try: #May not be present or may have other attributes - will give errors - Ignore these cases\n",
    "                    for elem2 in elem.value: #Double loop in cases that there is such attribute to get those of interest\n",
    "                        for elem3 in elem2:\n",
    "                            if elem3.tag==(0x00080104): #Attribute that conveys meaning of text\n",
    "                                if (elem3.value=='Calcium Volume' or elem3.value=='Calcium Mass' or \n",
    "                                    elem3.value=='Calcium Score' or elem3.value=='Number of Lesions' or \n",
    "                                    elem3.value=='Agatston Score Threshold'): #These are what we want to extract\n",
    "                \n",
    "                                    with open(open_path, 'a') as file: #Append information to txt file\n",
    "                                        file.write(str(elem3.value))\n",
    "                                        file.close()\n",
    "\n",
    "                            if elem3.tag==(0x0040a30a): #Attribute that has numeric values for the above\n",
    "                                \n",
    "                                with open(open_path, 'a') as file:  #Append information to txt file\n",
    "                                    file.write(str(elem3.value))\n",
    "                                    file.write('\\n')\n",
    "                                    file.close()\n",
    "\n",
    "                except: #Ignore when errors appear\n",
    "                    pass\n",
    "\n",
    "            if (elem.value=='LM' or elem.value=='LAD' or elem.value=='CX' or elem.value=='RCA' or elem.value=='Ca'\n",
    "                or elem.value=='U1' or elem.value=='U2'): #Attributes for which we need measurements\n",
    "\n",
    "                with open(open_path, 'a') as file: #Append attribute to txt file to be used to save to df below\n",
    "                    file.write(str(elem.value))\n",
    "                    file.write('\\n')\n",
    "                    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec5c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path): #For each SR file in path - Assume only SR files with relevant information from Syngo.via\n",
    "    SR=dicom.dcmread(path+'/'+file) #Load DICOM file\n",
    "    \n",
    "    open_path=save_path+'/'+str(SR.PatientID)+'.txt' #Path to save txt file\n",
    "    \n",
    "    with open(open_path, 'w') as f: #Create that file to write information to it\n",
    "        f.write('Information below about participant ' +str(SR.PatientID))\n",
    "        f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fd980c6",
   "metadata": {},
   "source": [
    "### We need to repeat the above since we get permission errors with txt files otherwise\n",
    "### We may even have to manually run the code below more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd78bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path): #Similar as above to extract information from the above\n",
    "    SR=dicom.dcmread(path+'/'+file)\n",
    "    open_path=save_path+'/'+str(SR.PatientID)+'.txt'\n",
    "    recurse(SR,open_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a7dc5d",
   "metadata": {},
   "source": [
    "### Add from txt files to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11d3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attributes to be added in REDCap\n",
    "column_names=['participant_id','total_lesions','total_artery_volume','total_artery_mass','total_artery_agatston', \n",
    "             'lm_artery_lesions','lm_artery_volume','lm_artery_mass','lm_artery_agatston',\n",
    "             'lad_artery_lesions','lad_artery_volume','lad_artery_mass','lad_artery_agatston',\n",
    "             'cx_artery_lesions','cx_artery_volume','cx_artery_mass','cx_artery_agatston',\n",
    "             'rca_artery_lesions','rca_artery_volume','rca_artery_mass','rca_artery_agatston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732400b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>total_lesions</th>\n",
       "      <th>total_artery_volume</th>\n",
       "      <th>total_artery_mass</th>\n",
       "      <th>total_artery_agatston</th>\n",
       "      <th>lm_artery_lesions</th>\n",
       "      <th>lm_artery_volume</th>\n",
       "      <th>lm_artery_mass</th>\n",
       "      <th>lm_artery_agatston</th>\n",
       "      <th>lad_artery_lesions</th>\n",
       "      <th>...</th>\n",
       "      <th>lad_artery_mass</th>\n",
       "      <th>lad_artery_agatston</th>\n",
       "      <th>cx_artery_lesions</th>\n",
       "      <th>cx_artery_volume</th>\n",
       "      <th>cx_artery_mass</th>\n",
       "      <th>cx_artery_agatston</th>\n",
       "      <th>rca_artery_lesions</th>\n",
       "      <th>rca_artery_volume</th>\n",
       "      <th>rca_artery_mass</th>\n",
       "      <th>rca_artery_agatston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [participant_id, total_lesions, total_artery_volume, total_artery_mass, total_artery_agatston, lm_artery_lesions, lm_artery_volume, lm_artery_mass, lm_artery_agatston, lad_artery_lesions, lad_artery_volume, lad_artery_mass, lad_artery_agatston, cx_artery_lesions, cx_artery_volume, cx_artery_mass, cx_artery_agatston, rca_artery_lesions, rca_artery_volume, rca_artery_mass, rca_artery_agatston]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=column_names) #Create df with above column names to be filled with extracted information\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9443857",
   "metadata": {},
   "source": [
    "#### It's assumed that we always have total Agatston, LM, LAD, CX, RCA, followed by the num of lesions, vol, mass and score. We also stored information for volume, score etc. followed exactly after attribute name without space (eg. 'Calcium Volume12.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "238fc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(save_path): #Loop over all txt files saved\n",
    "    \n",
    "    #Initialize empty series to add info for one participant below\n",
    "    empty=pd.DataFrame(index=np.arange(1),columns=column_names) \n",
    "    \n",
    "    with open(save_path+'/'+file,'r') as f: #Open each txt file as 'read-only' to save information to df\n",
    "        \n",
    "        #Initialize values to 0 as indicators that this attribute was found in txt and save to df\n",
    "        tot=0\n",
    "        lm=0\n",
    "        lad=0\n",
    "        cx=0\n",
    "        rca=0\n",
    "        \n",
    "        for line in f: #loop over each line of txt file\n",
    "            \n",
    "            if 'participant' in line: #If we have participant id in that line\n",
    "                empty['participant_id']=str(line.split('participant')[1][:-1]) #Save it to df, ignoring the '\\n' char\n",
    "                \n",
    "            #If each of the above attributes set their corresponding indicator to 1 to get in each of the loops below    \n",
    "            if 'Agatston' in line:\n",
    "                tot=1\n",
    "            if 'LM' in line:\n",
    "                lm=1\n",
    "            if 'LAD' in line:\n",
    "                lad=1\n",
    "            if 'CX' in line:\n",
    "                cx=1\n",
    "            if 'RCA' in line:\n",
    "                rca=1                \n",
    "    \n",
    "#For each attribute for which we got an indicator of 1, get into the corresponding loop, save num of lesion, volume,\n",
    "#mass and score to series and set the indicator to 0 to avoid get into it again when moving to next line \n",
    "#of the txt file.\n",
    "    \n",
    "            if tot==1:\n",
    "                if 'Number of Lesions' in line:\n",
    "                    empty['total_lesions']=line.split('Lesions')[-1][:-1] #last element the value, without newline\n",
    "                if 'Calcium Volume' in line:\n",
    "                    empty['total_artery_volume']=line.split('Volume')[-1][:-1]\n",
    "                if 'Calcium Mass' in line:\n",
    "                    empty['total_artery_mass']=line.split('Mass')[-1][:-1]\n",
    "                if 'Calcium Score' in line:\n",
    "                    empty['total_artery_agatston']=line.split('Score')[-1][:-1]\n",
    "                    tot=0\n",
    "    \n",
    "            if lm==1:\n",
    "                if 'Number of Lesions' in line:\n",
    "                    empty['lm_artery_lesions']=line.split('Lesions')[-1][:-1]\n",
    "                if 'Calcium Volume' in line:\n",
    "                    empty['lm_artery_volume']=line.split('Volume')[-1][:-1]\n",
    "                if 'Calcium Mass' in line:\n",
    "                    empty['lm_artery_mass']=line.split('Mass')[-1][:-1]\n",
    "                if 'Calcium Score' in line:\n",
    "                    empty['lm_artery_agatston']=line.split('Score')[-1][:-1]\n",
    "                    lm=0\n",
    "                    \n",
    "            if lad==1:\n",
    "                if 'Number of Lesions' in line:\n",
    "                    empty['lad_artery_lesions']=line.split('Lesions')[-1][:-1]\n",
    "                if 'Calcium Volume' in line:\n",
    "                    empty['lad_artery_volume']=line.split('Volume')[-1][:-1]\n",
    "                if 'Calcium Mass' in line:\n",
    "                    empty['lad_artery_mass']=line.split('Mass')[-1][:-1]\n",
    "                if 'Calcium Score' in line:\n",
    "                    empty['lad_artery_agatston']=line.split('Score')[-1][:-1]\n",
    "                    lad=0\n",
    "                    \n",
    "            if cx==1:\n",
    "                if 'Number of Lesions' in line:\n",
    "                    empty['cx_artery_lesions']=line.split('Lesions')[-1][:-1]\n",
    "                if 'Calcium Volume' in line:\n",
    "                    empty['cx_artery_volume']=line.split('Volume')[-1][:-1]\n",
    "                if 'Calcium Mass' in line:\n",
    "                    empty['cx_artery_mass']=line.split('Mass')[-1][:-1]\n",
    "                if 'Calcium Score' in line:\n",
    "                    empty['cx_artery_agatston']=line.split('Score')[-1][:-1]\n",
    "                    cx=0    \n",
    "                    \n",
    "            if rca==1:\n",
    "                if 'Number of Lesions' in line:\n",
    "                    empty['rca_artery_lesions']=line.split('Lesions')[-1][:-1]\n",
    "                if 'Calcium Volume' in line:\n",
    "                    empty['rca_artery_volume']=line.split('Volume')[-1][:-1]\n",
    "                if 'Calcium Mass' in line:\n",
    "                    empty['rca_artery_mass']=line.split('Mass')[-1][:-1]\n",
    "                if 'Calcium Score' in line:\n",
    "                    empty['rca_artery_agatston']=line.split('Score')[-1][:-1]\n",
    "                    rca=0             \n",
    "        \n",
    "        f.close() #Close the txt file of that specific participant once we loop over all its lines\n",
    "\n",
    "    df=df.append(empty) #Append information from series to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde05aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True) #Reset indices of df and drop 'index' column\n",
    "df #Should be in increasing participant id order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)] #Cases with null values - To be reviewed and extracted again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "496fe1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save=df[~df.isnull().any(axis=1)] #df to save non-nan cases\n",
    "# df_save.to_excel('CACS_REDCap.xlsx',index=False) #save to xlsx\n",
    "df_save.to_csv('CACS_REDCap.csv',index=False) #save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca22dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to run was 574.5030493736267 secs\n"
     ]
    }
   ],
   "source": [
    "end=time.time()\n",
    "print('Total time to run was',end-start, 'secs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
